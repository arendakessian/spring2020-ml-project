{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing poor model performance across multiple models, we sought to investigate whether there were differences between the training and dev set that caused this poor performance. To test this we took the training set, split it 80/20, vectorized train and dev separately, and downsampled train (adjusting the size of dev appropriately). \n",
    "\n",
    "This notebook outlines those steps, editing and executing all pre-processing steps from each of the individual notebooks in order to get a train and \"dev\" set that each come from the given training set. The last cell is a Naive Bayes model that shows that there even on the split training set, there are no significant differences in model performance. This means that the poor model results are not from differences between the training and dev sets but likely instead because this is just a difficult classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre_vectorization_feature_engineering.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# New series which has number of exclamation points in each review\n",
    "num_exclam_train = pd.Series(train['review'].str.count('!'))\n",
    "\n",
    "num_caps_train = (train['review'].str.extractall(r'(\\b[A-Z]{2,}\\b)') # extract all capitalized words with len >= 2\n",
    "                .groupby(level=0).size()                             # count by each index\n",
    "                .reindex(train['review'].index, fill_value=0))       # fill the missing with 0   \n",
    "\n",
    "with open('../data/train_num_exclam.pckl', 'wb') as f:\n",
    "    pickle.dump(num_exclam_train, f)\n",
    "    \n",
    "with open('../data/train_num_caps.pckl', 'wb') as f:\n",
    "    pickle.dump(num_caps_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureTransformation.ipynb\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "def engineered_df(df):\n",
    "    rolling_rev = []\n",
    "    user_dict = {}\n",
    "    for index,row in df.iterrows():\n",
    "        curr_date = row['date']\n",
    "        curr_user = row['user_id']\n",
    "        \n",
    "        if(curr_user not in user_dict):\n",
    "            dates = df.loc[df.user_id == curr_user,'date'].tolist()\n",
    "            dates.sort()\n",
    "            user_dict[curr_user] = dates\n",
    "        index = user_dict[curr_user].index(curr_date)\n",
    "        \n",
    "        rolling_rev.append(index)\n",
    "        \n",
    "    df['reviewsToDate'] = rolling_rev\n",
    "    return df\n",
    "\n",
    "train_engineered = engineered_df(train)\n",
    "\n",
    "with open('../data/train_reviewsToDate.pckl', 'wb') as f:\n",
    "     pickle.dump(train_engineered['reviewsToDate'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings.ipynb\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "with open('../data/train_ratings.pckl', 'wb') as f:\n",
    "    pickle.dump(train['rating'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "train_split, dev = train_test_split(train, train_size=0.8, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200699\n",
      "50175\n"
     ]
    }
   ],
   "source": [
    "print(len(train_split))\n",
    "print(len(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41308\n"
     ]
    }
   ],
   "source": [
    "# downsample.ipynb\n",
    "\n",
    "def downsample(df, pct_pos):\n",
    "    ''' \n",
    "    Borrowed from earlier project: https://github.com/kelseymarkey/\n",
    "    cook-county-mental-health-prediction/blob/master/Final_Data_Prep.py\n",
    "\n",
    "    takes in df and a percentage from 1 to 50\n",
    "    samples all label==1 cases, then samples from label==0 cases \n",
    "    until downsampled_df has pct_pos % positive cases, returns indices.\n",
    "    '''\n",
    "    # split into df by label\n",
    "    label_1 = df[df['label'] == 1]\n",
    "    label_0 = df[df['label'] == 0]\n",
    "\n",
    "    #count number of pos\n",
    "    count_label_1 = len(label_1)\n",
    "\n",
    "    #compute number of negative cases to sample\n",
    "    num_label_0 = count_label_1 * int(round((100 - pct_pos) / pct_pos))\n",
    "\n",
    "    #sample from negative cases\n",
    "    label_0_sample = label_0.sample(n=num_label_0, random_state=22)\n",
    "\n",
    "    #append sampled negative cases to all positive cases\n",
    "    downsampled_df = label_1.append(label_0_sample)\n",
    "\n",
    "    return list(downsampled_df.index)\n",
    "\n",
    "downsampled_idx_train = downsample(train_split, 50)\n",
    "\n",
    "print(len(downsampled_idx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    20654\n",
       "0    20654\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize-count.ipynb\n",
    "\n",
    "train_ds = train_split.loc[downsampled_idx_train]\n",
    "print(len(train_ds))\n",
    "train_ds['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10327\n"
     ]
    }
   ],
   "source": [
    "# need to shrink dev to be 20% of the dataset, now that train is downsampled (and much smaller)\n",
    "# to be 20% of the total it should be 1/4 the size of train_ds\n",
    "\n",
    "n = int(0.25 * len(train_ds))\n",
    "print(n)\n",
    "dev_resized = dev.sample(n = n, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize-count.ipynb\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "class StemmedDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        res = self[key] = port.stem(key)\n",
    "        return res\n",
    "\n",
    "stemmed = StemmedDict()\n",
    "port = PorterStemmer()\n",
    "analyzer = CountVectorizer(stop_words='english',\n",
    "                           ngram_range=(1, 3)).build_analyzer()\n",
    "\n",
    "def stem_words(doc):\n",
    "    return [' '.join([stemmed[word] for word in ngram.split()])\n",
    "            for ngram in analyzer(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize-count.ipynb\n",
    "\n",
    "n_feature_hashes = 2 ** 23  # we have at least 13m ngrams so we have a lot of collisions if taking 2^20\n",
    "\n",
    "cv = CountVectorizer(analyzer=stem_words)\n",
    "tf = TfidfVectorizer(analyzer=stem_words)\n",
    "bn = CountVectorizer(analyzer=stem_words, binary=True)  # binary version\n",
    "\n",
    "vectorizers = {'count': cv,\n",
    "               'tfidf': tf,\n",
    "               'binary': bn,\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished count\n",
      "finished tfidf\n",
      "finished binary\n"
     ]
    }
   ],
   "source": [
    "# vectorize-count.ipynb\n",
    "\n",
    "for name, vectorizer in vectorizers.items():\n",
    "    train_transformed = vectorizer.fit_transform(train_ds['review'])\n",
    "    print(f'finished {name}')\n",
    "\n",
    "    with open(f'../data/train_{name}_vectorized_80_20.pckl', 'wb') as f:\n",
    "        pickle.dump(train_transformed, f)\n",
    "    del train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished count\n",
      "finished tfidf\n",
      "finished binary\n"
     ]
    }
   ],
   "source": [
    "# vectorize-count.ipynb\n",
    "for name, vectorizer in vectorizers.items():\n",
    "    dev_transformed = vectorizer.transform(dev_resized['review'])\n",
    "    print(f'finished {name}')\n",
    "\n",
    "    with open(f'../data/dev_{name}_vectorized_80_20.pckl', 'wb') as f:\n",
    "        pickle.dump(dev_transformed, f)\n",
    "    del dev_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize-count.ipynb\n",
    "with open('../data/train_labels_80_20.pckl', 'wb') as f:\n",
    "    pickle.dump(train_ds['label'], f)\n",
    "    \n",
    "with open('../data/dev_labels_80_20.pckl', 'wb') as f:\n",
    "    pickle.dump(dev_resized['label'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat-features.ipynb \n",
    "from scipy import sparse\n",
    "\n",
    "train_indices = list(train_ds.index)\n",
    "dev_indices = list(dev_resized.index)\n",
    "    \n",
    "vectorizers = ['count', 'tfidf', 'binary']\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    for dataset in ['train', 'dev']:\n",
    "        with open(f'../data/{dataset}_{vectorizer}_vectorized_80_20.pckl', 'rb') as f:\n",
    "            vectorized_data = pickle.load(f)\n",
    "        \n",
    "        with open(f'../data/train_num_caps.pckl', 'rb') as f:\n",
    "            caps = pickle.load(f)\n",
    "        \n",
    "        with open(f'../data/train_num_exclam.pckl', 'rb') as f:\n",
    "            exclam = pickle.load(f)\n",
    "            \n",
    "        with open(f'../data/train_reviewsToDate.pckl', 'rb') as f:\n",
    "            rev_counts = pickle.load(f)\n",
    "            \n",
    "        with open(f'../data/train_ratings.pckl', 'rb') as f:\n",
    "            ratings = pickle.load(f)\n",
    "            \n",
    "        caps = caps.values.reshape(-1, 1)\n",
    "        exclam = exclam.values.reshape(-1, 1)\n",
    "        rev_counts = rev_counts.values.reshape(-1, 1)\n",
    "        ratings = ratings.values.reshape(-1, 1)\n",
    "                    \n",
    "        if dataset == 'train':\n",
    "            indices = train_indices\n",
    "        elif dataset == 'dev':\n",
    "            indices = dev_indices   \n",
    "\n",
    "        caps = caps[indices]\n",
    "        exclam = exclam[indices]\n",
    "        rev_counts = rev_counts[indices]\n",
    "        ratings = ratings[indices]\n",
    "        \n",
    "        # more features\n",
    "        \n",
    "        full_data = sparse.hstack((vectorized_data,\n",
    "                                   sparse.csr_matrix(caps),\n",
    "                                   sparse.csr_matrix(exclam),\n",
    "                                   sparse.csr_matrix(rev_counts),\n",
    "                                   sparse.csr_matrix(ratings),\n",
    "                                   # more features\n",
    "                                   ))\n",
    "\n",
    "        # for some reason, this isn't an actual CSR matrix...\n",
    "        full_data = full_data.tocsr()\n",
    "\n",
    "        with open(f'../data/{dataset}_{vectorizer}_subsampled_data_80_20.pckl', 'wb') as f:\n",
    "            pickle.dump(full_data, f)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Importing labels\n",
    "with open('../data/train_labels_80_20.pckl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)\n",
    "\n",
    "with open('../data/dev_labels_80_20.pckl', 'rb') as f:\n",
    "    dev_labels = pickle.load(f)\n",
    "    \n",
    "def get_data(dataset, vectorizer):\n",
    "    '''\n",
    "    returns feature matrix for specified dataset and vectorizer\n",
    "    @param dataset: string specifying dataset, \"train\",\"dev\",etc\n",
    "    @param vectorizer: string specifying vectorizer \"binary\",\"count\",etc\n",
    "\n",
    "    '''\n",
    "    with open(f'../data/{dataset}_{vectorizer}_subsampled_data_80_20.pckl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41308\n",
      "10327\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  count  -----\n",
      "Train AUC:        0.9983\n",
      "Train AP:         0.9984\n",
      "Train Precision:  0.9829\n",
      "Train Recall:     0.9851\n",
      "Dev   AUC:        0.7380\n",
      "Dev   AP:         0.2198\n",
      "Dev   Precision:  0.2242\n",
      "Dev   Recall:     0.4598\n",
      "-----  tfidf  -----\n",
      "Train AUC:        0.9632\n",
      "Train AP:         0.9779\n",
      "Train Precision:  0.9861\n",
      "Train Recall:     0.9290\n",
      "Dev   AUC:        0.7506\n",
      "Dev   AP:         0.2299\n",
      "Dev   Precision:  0.2048\n",
      "Dev   Recall:     0.6405\n",
      "-----  binary  -----\n",
      "Train AUC:        0.9998\n",
      "Train AP:         0.9998\n",
      "Train Precision:  0.9916\n",
      "Train Recall:     0.9968\n",
      "Dev   AUC:        0.6819\n",
      "Dev   AP:         0.1692\n",
      "Dev   Precision:  0.1738\n",
      "Dev   Recall:     0.4866\n"
     ]
    }
   ],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'alpha': loguniform(1e-4, 1e0)}\n",
    "\n",
    "vectorizers = ['count', 'tfidf', 'binary'] \n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    print('----- ', vectorizer, ' -----')\n",
    "    train = get_data('train', vectorizer) \n",
    "    dev = get_data('dev', vectorizer) \n",
    "\n",
    "    nb_multi = MultinomialNB()  \n",
    "\n",
    "    # run randomized search\n",
    "    random_search = RandomizedSearchCV(nb_multi, param_distributions=param_dist)\n",
    "\n",
    "    random_search.fit(train, train_labels)\n",
    "\n",
    "    nb_train = random_search.predict(train)\n",
    "    nb_dev = random_search.predict(dev)\n",
    "    nb_train_proba = random_search.predict_proba(train)\n",
    "    nb_dev_proba = random_search.predict_proba(dev)\n",
    "    \n",
    "    nb_train_auc = roc_auc_score(train_labels, nb_train_proba[:, 1])\n",
    "    nb_train_ap = average_precision_score(train_labels, nb_train_proba[:, 1])\n",
    "    nb_train_recall = recall_score(train_labels, nb_train)\n",
    "    nb_train_prec = precision_score(train_labels, nb_train)\n",
    "    nb_dev_auc = roc_auc_score(dev_labels, nb_dev_proba[:, 1])\n",
    "    nb_dev_ap = average_precision_score(dev_labels, nb_dev_proba[:, 1])\n",
    "    nb_dev_recall = recall_score(dev_labels, nb_dev)\n",
    "    nb_dev_prec = precision_score(dev_labels, nb_dev)\n",
    "\n",
    "    print(f'Train AUC:        {nb_train_auc:.4f}\\n'\n",
    "          f'Train AP:         {nb_train_ap:.4f}\\n'\n",
    "          f'Train Precision:  {nb_train_prec:.4f}\\n'\n",
    "          f'Train Recall:     {nb_train_recall:.4f}\\n'\n",
    "          f'Dev   AUC:        {nb_dev_auc:.4f}\\n'\n",
    "          f'Dev   AP:         {nb_dev_ap:.4f}\\n'\n",
    "          f'Dev   Precision:  {nb_dev_prec:.4f}\\n'\n",
    "          f'Dev   Recall:     {nb_dev_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
