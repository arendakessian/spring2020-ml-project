{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import random\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset,vectorizer):\n",
    "    '''\n",
    "    returns feature matrix for specified dataset and vectorizer\n",
    "    @param dataset: string specifying dataset, \"train\",\"dev\",etc\n",
    "    @param vectorizer: string specifying vectorizer \"binary\",\"count\",etc\n",
    "\n",
    "    '''\n",
    "    with open(f'../data/{dataset}_{vectorizer}_downsampled_data.pckl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting train_y and dev_y\n",
    "with open('../data/train_labels.pckl', 'rb') as f:\n",
    "    trainY = pickle.load(f)\n",
    "\n",
    "with open('../data/dev_labels.pckl', 'rb') as f:\n",
    "    devY = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "count\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
      "                                        early_stopping=True, eta0=1.0,\n",
      "                                        fit_intercept=True, max_iter=1000,\n",
      "                                        n_iter_no_change=5, n_jobs=None,\n",
      "                                        penalty=None, random_state=0,\n",
      "                                        shuffle=True, tol=0.001,\n",
      "                                        validation_fraction=0.1, verbose=0,\n",
      "                                        warm_start=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'eta0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D88641DCF8>,\n",
      "                                        'fit_intercept': [True, False],\n",
      "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
      "                                                    None]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.6793640342383516\n",
      "Train AP 0.625581180510904\n",
      "Val AUC 0.6572560315512207\n",
      "Val AP 0.15545829056417584\n",
      "--------------------------\n",
      "--------------------------\n",
      "tfidf\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
      "                                        early_stopping=True, eta0=1.0,\n",
      "                                        fit_intercept=True, max_iter=1000,\n",
      "                                        n_iter_no_change=5, n_jobs=None,\n",
      "                                        penalty=None, random_state=0,\n",
      "                                        shuffle=True, tol=0.001,\n",
      "                                        validation_fraction=0.1, verbose=0,\n",
      "                                        warm_start=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'eta0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D88641DCF8>,\n",
      "                                        'fit_intercept': [True, False],\n",
      "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
      "                                                    None]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.6862194507920524\n",
      "Train AP 0.6196525665975021\n",
      "Val AUC 0.6874015978123182\n",
      "Val AP 0.1590590358488763\n",
      "--------------------------\n",
      "--------------------------\n",
      "hashing\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
      "                                        early_stopping=True, eta0=1.0,\n",
      "                                        fit_intercept=True, max_iter=1000,\n",
      "                                        n_iter_no_change=5, n_jobs=None,\n",
      "                                        penalty=None, random_state=0,\n",
      "                                        shuffle=True, tol=0.001,\n",
      "                                        validation_fraction=0.1, verbose=0,\n",
      "                                        warm_start=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'eta0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D88641DCF8>,\n",
      "                                        'fit_intercept': [True, False],\n",
      "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
      "                                                    None]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.6865293001278129\n",
      "Train AP 0.6198470347894656\n",
      "Val AUC 0.6848234757854506\n",
      "Val AP 0.15731827939572177\n",
      "--------------------------\n",
      "--------------------------\n",
      "binary\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
      "                                        early_stopping=True, eta0=1.0,\n",
      "                                        fit_intercept=True, max_iter=1000,\n",
      "                                        n_iter_no_change=5, n_jobs=None,\n",
      "                                        penalty=None, random_state=0,\n",
      "                                        shuffle=True, tol=0.001,\n",
      "                                        validation_fraction=0.1, verbose=0,\n",
      "                                        warm_start=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'eta0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D88641DCF8>,\n",
      "                                        'fit_intercept': [True, False],\n",
      "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
      "                                                    None]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.6926294589255975\n",
      "Train AP 0.6241964155012278\n",
      "Val AUC 0.67241608461229\n",
      "Val AP 0.15122238825149317\n",
      "--------------------------\n",
      "--------------------------\n",
      "hashing_binary\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=Perceptron(alpha=0.0001, class_weight=None,\n",
      "                                        early_stopping=True, eta0=1.0,\n",
      "                                        fit_intercept=True, max_iter=1000,\n",
      "                                        n_iter_no_change=5, n_jobs=None,\n",
      "                                        penalty=None, random_state=0,\n",
      "                                        shuffle=True, tol=0.001,\n",
      "                                        validation_fraction=0.1, verbose=0,\n",
      "                                        warm_start=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'eta0': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D88641DCF8>,\n",
      "                                        'fit_intercept': [True, False],\n",
      "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
      "                                                    None]},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.6568031294782912\n",
      "Train AP 0.5948140229126471\n",
      "Val AUC 0.6548281546463773\n",
      "Val AP 0.14229906457354638\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "\n",
    "vectorizers = ['count', 'tfidf', 'hashing', 'binary', 'hashing_binary']\n",
    "\n",
    "param_grid = {\"penalty\":[\"l1\",\"l2\",\"elasticnet\",None],\"fit_intercept\":[True,False],\"eta0\":sp_rand()}\n",
    "\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    print(\"--------------------------\")\n",
    "    print(vectorizer)\n",
    "    trainX = get_data(\"train\",vectorizer)\n",
    "    valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "    clf = Perceptron(early_stopping=True)\n",
    "    \n",
    "    rsearch = RandomizedSearchCV(n_jobs=-1, estimator=clf,param_distributions=param_grid)\n",
    "    \n",
    "    rsearch.fit(trainX,trainY)\n",
    "    \n",
    "    print(rsearch)\n",
    "    \n",
    "    ytrain_score = rsearch.predict(trainX)\n",
    "    yval_score = rsearch.predict(valX)\n",
    "    \n",
    "    \n",
    "    print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "    print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "    print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "    print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "count\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                                       fit_intercept=True, intercept_scaling=1,\n",
      "                                       loss='squared_hinge', max_iter=1000,\n",
      "                                       multi_class='ovr', penalty='l2',\n",
      "                                       random_state=None, tol=0.0001,\n",
      "                                       verbose=0),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D8862DBF60>,\n",
      "                                        'loss': ['squared_hinge'],\n",
      "                                        'penalty': ['l1', 'l2']},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.7070955497889151\n",
      "Train AP 0.6376239659555522\n",
      "Val AUC 0.6902978535003452\n",
      "Val AP 0.16065057843677116\n",
      "--------------------------\n",
      "--------------------------\n",
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                                       fit_intercept=True, intercept_scaling=1,\n",
      "                                       loss='squared_hinge', max_iter=1000,\n",
      "                                       multi_class='ovr', penalty='l2',\n",
      "                                       random_state=None, tol=0.0001,\n",
      "                                       verbose=0),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D8862DBF60>,\n",
      "                                        'loss': ['squared_hinge'],\n",
      "                                        'penalty': ['l1', 'l2']},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.7560130136721019\n",
      "Train AP 0.6845466344796391\n",
      "Val AUC 0.6854553683558137\n",
      "Val AP 0.1642965471538151\n",
      "--------------------------\n",
      "--------------------------\n",
      "hashing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                                       fit_intercept=True, intercept_scaling=1,\n",
      "                                       loss='squared_hinge', max_iter=1000,\n",
      "                                       multi_class='ovr', penalty='l2',\n",
      "                                       random_state=None, tol=0.0001,\n",
      "                                       verbose=0),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D8862DBF60>,\n",
      "                                        'loss': ['squared_hinge'],\n",
      "                                        'penalty': ['l1', 'l2']},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.6963476509547233\n",
      "Train AP 0.629565052463863\n",
      "Val AUC 0.6810362232859807\n",
      "Val AP 0.15730174467496144\n",
      "--------------------------\n",
      "--------------------------\n",
      "binary\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                                       fit_intercept=True, intercept_scaling=1,\n",
      "                                       loss='squared_hinge', max_iter=1000,\n",
      "                                       multi_class='ovr', penalty='l2',\n",
      "                                       random_state=None, tol=0.0001,\n",
      "                                       verbose=0),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D8862DBF60>,\n",
      "                                        'loss': ['squared_hinge'],\n",
      "                                        'penalty': ['l1', 'l2']},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.7647275262403656\n",
      "Train AP 0.6906379222780863\n",
      "Val AUC 0.6893388059356633\n",
      "Val AP 0.1619395745080802\n",
      "--------------------------\n",
      "--------------------------\n",
      "hashing_binary\n",
      "RandomizedSearchCV(cv=None, error_score=nan,\n",
      "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                                       fit_intercept=True, intercept_scaling=1,\n",
      "                                       loss='squared_hinge', max_iter=1000,\n",
      "                                       multi_class='ovr', penalty='l2',\n",
      "                                       random_state=None, tol=0.0001,\n",
      "                                       verbose=0),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
      "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D8862DBF60>,\n",
      "                                        'loss': ['squared_hinge'],\n",
      "                                        'penalty': ['l1', 'l2']},\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring=None, verbose=0)\n",
      "Train AUC 0.7066114102017893\n",
      "Train AP 0.6391124874575902\n",
      "Val AUC 0.6870898351491526\n",
      "Val AP 0.1610760597987767\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import scipy.stats\n",
    "param_grid = {\"penalty\":[\"l1\",\"l2\"],\"loss\":[\"squared_hinge\"],\"C\":scipy.stats.reciprocal(a=1e-4,b=1e2)}\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    print(\"--------------------------\")\n",
    "    print(vectorizer)\n",
    "    trainX = get_data(\"train\",vectorizer)\n",
    "    valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "    \n",
    "    rsearch = RandomizedSearchCV(n_jobs=-1, estimator=clf,param_distributions=param_grid)\n",
    "    \n",
    "    rsearch.fit(trainX,trainY)\n",
    "    \n",
    "    print(rsearch)\n",
    "    \n",
    "    ytrain_score = rsearch.predict(trainX)\n",
    "    yval_score = rsearch.predict(valX)\n",
    "    \n",
    "    \n",
    "    print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "    print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "    print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "    print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "rbf\n",
      "count\n",
      "1000\n",
      "Train AUC 0.6431891242883149\n",
      "Train AP 0.5846210445619413\n",
      "Val AUC 0.48710227133723677\n",
      "Val AP 0.1000083194710632\n",
      "-----------------------------------\n",
      "---------------------------------\n",
      "rbf\n",
      "count\n",
      "5000\n",
      "Train AUC 0.6435958015415004\n",
      "Train AP 0.5849188233638523\n",
      "Val AUC 0.4377501848438885\n",
      "Val AP 0.093414327577478\n",
      "-----------------------------------\n",
      "---------------------------------\n",
      "rbf\n",
      "count\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "vectorizers = ['count', 'tfidf', 'hashing', 'binary', 'hashing_binary']\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    for kernel in [\"rbf\",\"polynomial\"]:\n",
    "        for n in [1000,5000,10000,25000,45000]:\n",
    "            print(\"---------------------------------\")\n",
    "            print(kernel)\n",
    "            print(vectorizer)\n",
    "            print(n)\n",
    "            trainX = get_data(\"train\",vectorizer)\n",
    "            valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "            clf = svm.LinearSVC(max_iter=400,tol=1e-2,C=.1)\n",
    "   \n",
    "    \n",
    "            if(kernel==\"rbf\"):\n",
    "                feature_map_nystroem = Nystroem(kernel=kernel,n_components=n)\n",
    "        \n",
    "            else:\n",
    "                feature_map_nystroem = Nystroem(kernel=kernel,degree=2.0,n_components=n)\n",
    "        \n",
    "            train_transformed = feature_map_nystroem.fit_transform(trainX)\n",
    "    \n",
    "            val_transformed = feature_map_nystroem.fit_transform(valX)\n",
    "\n",
    "    \n",
    "            clf.fit(train_transformed,trainY)\n",
    "    \n",
    "            ytrain_score = clf.predict(train_transformed)\n",
    "            yval_score = clf.predict(val_transformed)\n",
    "    \n",
    "    \n",
    "            print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "            print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "            print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "            print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    \n",
    "            print(\"-----------------------------------\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
