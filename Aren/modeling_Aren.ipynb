{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import random\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset,vectorizer):\n",
    "    '''\n",
    "    returns feature matrix for specified dataset and vectorizer\n",
    "    @param dataset: string specifying dataset, \"train\",\"dev\",etc\n",
    "    @param vectorizer: string specifying vectorizer \"binary\",\"count\",etc\n",
    "\n",
    "    '''\n",
    "    with open(f'../data/{dataset}_{vectorizer}_subsampled_data.pckl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting train_y and dev_y\n",
    "with open('../data/train_labels.pckl', 'rb') as f:\n",
    "    trainY = pickle.load(f)\n",
    "\n",
    "with open('../data/dev_labels.pckl', 'rb') as f:\n",
    "    devY = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "count\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=True,\n",
      "           eta0=0.9636627605010293, fit_intercept=True, max_iter=1000,\n",
      "           n_iter_no_change=5, n_jobs=None, penalty='l2', random_state=0,\n",
      "           shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "           warm_start=False)\n",
      "Val AUC 0.7060673349928509\n",
      "Val AP 0.17427758321442435\n",
      "--------------------------\n",
      "--------------------------\n",
      "tfidf\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=True,\n",
      "           eta0=0.4375872112626925, fit_intercept=True, max_iter=1000,\n",
      "           n_iter_no_change=5, n_jobs=None, penalty='l1', random_state=0,\n",
      "           shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "           warm_start=False)\n",
      "Val AUC 0.7394226525165951\n",
      "Val AP 0.2157023479250944\n",
      "--------------------------\n",
      "--------------------------\n",
      "binary\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=True,\n",
      "           eta0=0.4236547993389047, fit_intercept=False, max_iter=1000,\n",
      "           n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "           random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "           verbose=0, warm_start=False)\n",
      "Val AUC 0.6496913251471955\n",
      "Val AP 0.14967082209990168\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "\n",
    "vectorizers = ['count',\n",
    "               'tfidf',\n",
    "               #'hashing',\n",
    "               'binary',\n",
    "               #'hashing_binary',\n",
    "               ]\n",
    "\n",
    "param_grid = {\"penalty\":[\"l1\",\"l2\",\"elasticnet\",None],\"fit_intercept\":[True,False],\"eta0\":sp_rand()}\n",
    "\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    print(\"--------------------------\")\n",
    "    print(vectorizer)\n",
    "    trainX = get_data(\"train\",vectorizer)\n",
    "    valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "    clf = Perceptron(early_stopping=True)\n",
    "    \n",
    "    rsearch = RandomizedSearchCV(n_jobs=-1, random_state=0, estimator=clf,param_distributions=param_grid)\n",
    "    \n",
    "    rsearch.fit(trainX,trainY)\n",
    "    \n",
    "    print(rsearch.best_estimator_)\n",
    "    \n",
    "    #ytrain_score = rsearch.predict_proba(trainX)\n",
    "    yval_score = rsearch.decision_function(valX)\n",
    "    \n",
    "    \n",
    "    #print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "    #print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "    print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "    print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "count\n",
      "LinearSVC(C=0.00017229584247800946, class_weight=None, dual=True,\n",
      "          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "          max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      "          tol=0.0001, verbose=0)\n",
      "Val AUC 0.7507259837160689\n",
      "Val AP 0.2289730118025493\n",
      "--------------------------\n",
      "--------------------------\n",
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.0484152602408974, class_weight=None, dual=True,\n",
      "          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "          max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      "          tol=0.0001, verbose=0)\n",
      "Val AUC 0.7522518462302721\n",
      "Val AP 0.23281083589105311\n",
      "--------------------------\n",
      "--------------------------\n",
      "binary\n",
      "LinearSVC(C=0.0004964258537479101, class_weight=None, dual=True,\n",
      "          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "          max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      "          tol=0.0001, verbose=0)\n",
      "Val AUC 0.7493476395367485\n",
      "Val AP 0.23021511582458373\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import scipy.stats\n",
    "param_grid = {\"penalty\":[\"l1\",\"l2\"],\"loss\":[\"squared_hinge\"],\"C\":scipy.stats.reciprocal(a=1e-4,b=1e2)}\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    print(\"--------------------------\")\n",
    "    print(vectorizer)\n",
    "    trainX = get_data(\"train\",vectorizer)\n",
    "    valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "    \n",
    "    rsearch = RandomizedSearchCV(n_jobs=-1, estimator=clf,param_distributions=param_grid)\n",
    "    \n",
    "    rsearch.fit(trainX,trainY)\n",
    "    \n",
    "    print(rsearch.best_estimator_)\n",
    "    \n",
    "    #ytrain_score = rsearch.predict(trainX)\n",
    "    yval_score = rsearch.decision_function(valX)\n",
    "    \n",
    "    \n",
    "    #print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "    #print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "    print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "    print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "tfidf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC 0.7515879372713236\n",
      "Val AP 0.23180908887441007\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import scipy.stats\n",
    "param_grid = {\"penalty\":[\"l1\",\"l2\"],\"loss\":[\"squared_hinge\"],\"C\":scipy.stats.reciprocal(a=1e-4,b=1e2)}\n",
    "\n",
    "for vectorizer in ['tfidf']:\n",
    "    print(\"--------------------------\")\n",
    "    print(vectorizer)\n",
    "    trainX = get_data(\"train\",vectorizer)\n",
    "    valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "    clf = LinearSVC(C=0.18590843630169634, class_weight=None, dual=True,\n",
    "          fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
    "          max_iter=5000, multi_class='ovr', penalty='l2', random_state=0,\n",
    "          tol=0.0001, verbose=0)\n",
    "    \n",
    "    #rsearch = RandomizedSearchCV(n_jobs=-1, random_state=0, estimator=clf,param_distributions=param_grid)\n",
    "    \n",
    "    clf.fit(trainX,trainY)\n",
    "    \n",
    "    #print(rsearch.best_estimator_)\n",
    "    #print(rsearch.best_estimator_.n_iter_)\n",
    "    \n",
    "    #ytrain_score = rsearch.predict(trainX)\n",
    "    yval_score = clf.decision_function(valX)\n",
    "    \n",
    "    \n",
    "    #print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "    #print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "    print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "    print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/best_svm_tfidf.pckl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b0fc1652d62b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/best_svm_tfidf.pckl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/best_svm_tfidf.pckl'"
     ]
    }
   ],
   "source": [
    "with open('../data/best_svm_tfidf.pckl', 'rb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "rbf\n",
      "count\n",
      "1000\n",
      "Train AUC 0.6431891242883149\n",
      "Train AP 0.5846210445619413\n",
      "Val AUC 0.48710227133723677\n",
      "Val AP 0.1000083194710632\n",
      "-----------------------------------\n",
      "---------------------------------\n",
      "rbf\n",
      "count\n",
      "5000\n",
      "Train AUC 0.6435958015415004\n",
      "Train AP 0.5849188233638523\n",
      "Val AUC 0.4377501848438885\n",
      "Val AP 0.093414327577478\n",
      "-----------------------------------\n",
      "---------------------------------\n",
      "rbf\n",
      "count\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "vectorizers = ['count', 'tfidf', 'hashing', 'binary', 'hashing_binary']\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    for kernel in [\"rbf\",\"polynomial\"]:\n",
    "        for n in [1000,5000,10000,25000,45000]:\n",
    "            print(\"---------------------------------\")\n",
    "            print(kernel)\n",
    "            print(vectorizer)\n",
    "            print(n)\n",
    "            trainX = get_data(\"train\",vectorizer)\n",
    "            valX = get_data(\"dev\",vectorizer)\n",
    "    \n",
    "            clf = svm.LinearSVC(max_iter=400,tol=1e-2,C=.1)\n",
    "   \n",
    "    \n",
    "            if(kernel==\"rbf\"):\n",
    "                feature_map_nystroem = Nystroem(kernel=kernel,n_components=n)\n",
    "        \n",
    "            else:\n",
    "                feature_map_nystroem = Nystroem(kernel=kernel,degree=2.0,n_components=n)\n",
    "        \n",
    "            train_transformed = feature_map_nystroem.fit_transform(trainX)\n",
    "    \n",
    "            val_transformed = feature_map_nystroem.fit_transform(valX)\n",
    "\n",
    "    \n",
    "            clf.fit(train_transformed,trainY)\n",
    "    \n",
    "            ytrain_score = clf.predict(train_transformed)\n",
    "            yval_score = clf.predict(val_transformed)\n",
    "    \n",
    "    \n",
    "            print(\"Train AUC\",roc_auc_score(trainY,ytrain_score))\n",
    "            print(\"Train AP\",average_precision_score(trainY,ytrain_score))\n",
    "            print(\"Val AUC\",roc_auc_score(devY,yval_score))\n",
    "            print(\"Val AP\",average_precision_score(devY,yval_score))\n",
    "    \n",
    "            print(\"-----------------------------------\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
